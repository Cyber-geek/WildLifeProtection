{"cells":[{"metadata":{"_uuid":"4b795605-82bf-4293-80d6-2d7cddc70664","_cell_guid":"2e00e4d2-d314-4022-86c6-9c0915c9e490","trusted":true},"cell_type":"markdown","source":"# Identification of illegal wildlife trade\n\nBreakdown of this notebook:\n1. **Loading the 32x32 dataset**: Load the data generated in *Reducing Image Sizes to 32x32*.\n2. **Create Callback for F1 Score**: F1-macro score is the official metric of the competition. We create a callback to keep track of that value as we train the model.\n3. **Creating and Training the Model**: Create a DenseNet model, and load weights pretrained on ImageNet. Train it on the entire dataset.\n4. **Evaluation**: Display the plots from the training history.\n5. **Submission**: Run predictions with `model.predict`, and create submission csv file.\n\n### References\n\n\n* [Reducing Image Sizes to 32x32](https://www.kaggle.com/xhlulu/reducing-image-sizes-to-32x32): Image data (`X_train`, `X_test`) come from the output of this kernel.\n* [How to compute f1 score for each epoch in Keras](https://medium.com/@thongonary/how-to-compute-f1-score-for-each-epoch-in-keras-a1acd17715a2): Needed to compute the F1 Score after each epoch.\n* [CNN Baseline - iWildCam 2019](https://www.kaggle.com/xhlulu/cnn-baseline-iwildcam-2019): This is a fork of this notebook."},{"metadata":{"_uuid":"70da3311-d2df-4d30-9202-2d76d7d4d1a8","_cell_guid":"eb1b8f2b-cf99-4398-ab66-e1d39a7586d8","trusted":true},"cell_type":"code","source":"import os\nimport json\n\nimport numpy as np\nimport pandas as pd\nimport keras\nfrom keras import layers\nfrom keras.applications import DenseNet121\nfrom keras.callbacks import Callback, ModelCheckpoint\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.layers import Dense, Dropout, Activation, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.models import Sequential\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score","execution_count":1,"outputs":[{"output_type":"stream","text":"Using TensorFlow backend.\n","name":"stderr"}]},{"metadata":{"_uuid":"994f5419-c359-431e-b2af-e819bf4f609e","_cell_guid":"2fb17ed1-a3c6-4867-b526-8d67de361376","trusted":true},"cell_type":"code","source":"os.listdir('../input')","execution_count":2,"outputs":[{"output_type":"execute_result","execution_count":2,"data":{"text/plain":"['densenet-keras', 'reducing-image-sizes-to-32x32', 'iwildcam-2019-fgvc6']"},"metadata":{}}]},{"metadata":{"_uuid":"571b563e-eff6-47ca-aea3-dc2c0c9ec372","_cell_guid":"5de3d481-a0f8-4117-905f-b414e58c34d8","trusted":true},"cell_type":"markdown","source":"## Loading the 32x32 dataset"},{"metadata":{"_uuid":"341025c8-c3c7-4755-bae2-d02c39ed67a8","_cell_guid":"f99eb109-01f7-4659-ae39-df1eaaa6d0ca","trusted":true},"cell_type":"code","source":"# The data, split between train and test sets:\nx_train = np.load('../input/reducing-image-sizes-to-32x32/X_train.npy')\nx_test = np.load('../input/reducing-image-sizes-to-32x32/X_test.npy')\ny_train = np.load('../input/reducing-image-sizes-to-32x32/y_train.npy')\n\nprint('x_train shape:', x_train.shape)\nprint(x_train.shape[0], 'train samples')\nprint(x_test.shape[0], 'test samples')","execution_count":3,"outputs":[{"output_type":"stream","text":"x_train shape: (196299, 32, 32, 3)\n196299 train samples\n153730 test samples\n","name":"stdout"}]},{"metadata":{"_uuid":"f04f652a-d515-413e-8adf-1d0d7e1a2a9a","_cell_guid":"768ebeb8-c034-4ff8-9eeb-9ab06dc748eb","trusted":true},"cell_type":"code","source":"# Convert the images to float and scale it to a range of 0 to 1\nx_train = x_train.astype('float32')\nx_test = x_test.astype('float32')\nx_train /= 255.\nx_test /= 255.","execution_count":4,"outputs":[]},{"metadata":{"_uuid":"68cb8589-f14a-40c7-ba08-ec39c8b79c23","_cell_guid":"e22e1f55-fc41-4eb6-9940-86dbd24c06f3","trusted":true},"cell_type":"markdown","source":"## Create Callback for F1 score"},{"metadata":{"_uuid":"e6e73ddc-a70f-432d-9751-bdd9e650542f","_cell_guid":"dc1fa389-edf4-430c-b845-8dc4eba88a9b","trusted":true},"cell_type":"code","source":"class Metrics(Callback):\n    def on_train_begin(self, logs={}):\n        self.val_f1s = []\n        self.val_recalls = []\n        self.val_precisions = []\n\n    def on_epoch_end(self, epoch, logs={}):\n        X_val, y_val = self.validation_data[:2]\n        y_pred = self.model.predict(X_val)\n\n        y_pred_cat = keras.utils.to_categorical(\n            y_pred.argmax(axis=1),\n            num_classes=14\n        )\n\n        _val_f1 = f1_score(y_val, y_pred_cat, average='macro')\n        _val_recall = recall_score(y_val, y_pred_cat, average='macro')\n        _val_precision = precision_score(y_val, y_pred_cat, average='macro')\n\n        self.val_f1s.append(_val_f1)\n        self.val_recalls.append(_val_recall)\n        self.val_precisions.append(_val_precision)\n\n        print((f\"val_f1: {_val_f1:.4f}\"\n               f\" — val_precision: {_val_precision:.4f}\"\n               f\" — val_recall: {_val_recall:.4f}\"))\n\n        return\n\nf1_metrics = Metrics()","execution_count":5,"outputs":[]},{"metadata":{"_uuid":"bef5e2d6-820d-4bcc-a33d-b2a8b45fd4d9","_cell_guid":"0ad2cfd1-caea-4e73-9ee5-46643016fb61","trusted":true},"cell_type":"markdown","source":"## Creating and Training the Model"},{"metadata":{"_uuid":"b758806d-3926-4987-9af4-445893864e66","_cell_guid":"f924d7a2-68ea-457e-bfba-306d8caa1c54","trusted":true},"cell_type":"code","source":"densenet = DenseNet121(\n    weights='../input/densenet-keras/DenseNet-BC-121-32-no-top.h5',\n    include_top=False,\n    input_shape=(32,32,3)\n)\n","execution_count":6,"outputs":[{"output_type":"stream","text":"WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nColocations handled automatically by placer.\n","name":"stdout"}]},{"metadata":{"_uuid":"2150ef0b-c44a-49fa-b998-98411fca678a","_cell_guid":"4eca71da-9f95-4f3c-b47e-2f0071cc866e","trusted":true},"cell_type":"code","source":"model = Sequential()\nmodel.add(densenet)\nmodel.add(layers.GlobalAveragePooling2D())\nmodel.add(layers.Dense(14, activation='softmax'))","execution_count":7,"outputs":[]},{"metadata":{"_uuid":"a0550d59-5e8d-446c-9a17-b53fa4e0dd8d","_cell_guid":"186dc87b-edfb-4ec3-b7ff-eebaf18dd7f1","trusted":true},"cell_type":"code","source":"model.compile(loss='categorical_crossentropy',\n              optimizer='adam',\n              metrics=['accuracy'])\n\nmodel.summary()","execution_count":8,"outputs":[{"output_type":"stream","text":"_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndensenet121 (Model)          (None, 1, 1, 1024)        7037504   \n_________________________________________________________________\nglobal_average_pooling2d_1 ( (None, 1024)              0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 14)                14350     \n=================================================================\nTotal params: 7,051,854\nTrainable params: 6,968,206\nNon-trainable params: 83,648\n_________________________________________________________________\n","name":"stdout"}]},{"metadata":{"_uuid":"6b3e77ce-0739-44ed-8288-390550943f85","_cell_guid":"f813fb49-5c20-4a66-bd49-974cf202f49e","trusted":true},"cell_type":"code","source":"model.compile(\n    loss='categorical_crossentropy',\n    optimizer='adam',\n    metrics=['accuracy']\n)\n\ncheckpoint = ModelCheckpoint(\n    'model.h5', \n    monitor='val_acc', \n    verbose=1, \n    save_best_only=True, \n    save_weights_only=False,\n    mode='auto'\n)\n\nhistory = model.fit(\n    x=x_train,\n    y=y_train,\n    batch_size=64,\n    epochs=7,\n    callbacks=[checkpoint, f1_metrics],\n    validation_split=0.1\n)","execution_count":null,"outputs":[{"output_type":"stream","text":"WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse tf.cast instead.\nTrain on 176669 samples, validate on 19630 samples\nEpoch 1/7\n176669/176669 [==============================] - 407s 2ms/step - loss: 0.7144 - acc: 0.7733 - val_loss: 0.5985 - val_acc: 0.8034\n\nEpoch 00001: val_acc improved from -inf to 0.80336, saving model to model.h5\nval_f1: 0.3766 — val_precision: 0.4432 — val_recall: 0.3590\nEpoch 2/7\n    64/176669 [..............................] - ETA: 6:11 - loss: 0.8084 - acc: 0.6875","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n  'precision', 'predicted', average, warn_for)\n/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n  'precision', 'predicted', average, warn_for)\n","name":"stderr"},{"output_type":"stream","text":"176669/176669 [==============================] - 377s 2ms/step - loss: 0.5369 - acc: 0.8240 - val_loss: 0.4888 - val_acc: 0.8394\n\nEpoch 00002: val_acc improved from 0.80336 to 0.83943, saving model to model.h5\nval_f1: 0.5043 — val_precision: 0.5909 — val_recall: 0.5061\nEpoch 3/7\n176669/176669 [==============================] - 377s 2ms/step - loss: 0.4515 - acc: 0.8496 - val_loss: 0.4534 - val_acc: 0.8499\n\nEpoch 00003: val_acc improved from 0.83943 to 0.84992, saving model to model.h5\nval_f1: 0.5464 — val_precision: 0.6116 — val_recall: 0.5281\nEpoch 4/7\n174720/176669 [============================>.] - ETA: 3s - loss: 0.3811 - acc: 0.8710","name":"stdout"}]},{"metadata":{"_uuid":"15f4fa12-3d17-475c-a40b-c1c6978afed8","_cell_guid":"f77f4ded-2738-4eb5-a18f-d9751b983919","trusted":true},"cell_type":"markdown","source":"## Evaluation"},{"metadata":{"_uuid":"5f052589-448f-4107-be28-05d22480c14f","_cell_guid":"cf131422-d719-4d81-abd1-bc1cfaa37773","trusted":true},"cell_type":"code","source":"with open('history.json', 'w') as f:\n    json.dump(history.history, f)\n\nhistory_df = pd.DataFrame(history.history)\nhistory_df['val_f1'] = f1_metrics.val_f1s\nhistory_df['val_precision'] = f1_metrics.val_precisions\nhistory_df['val_recall'] = f1_metrics.val_recalls\nhistory_df[['loss', 'val_loss']].plot()\nhistory_df[['acc', 'val_acc']].plot()\nhistory_df[['val_f1', 'val_precision', 'val_recall']].plot()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"77cc8b5a-c09a-4031-9bd1-e1599e6787bf","_cell_guid":"95b7f12a-2023-4591-b9c7-b1ce543dc646","trusted":true},"cell_type":"code","source":"model.load_weights('model.h5')\ny_test = model.predict(x_test)\n\nsubmission_df = pd.read_csv('../input/iwildcam-2019-fgvc6/sample_submission.csv')\nsubmission_df['Predicted'] = y_test.argmax(axis=1)\n\nprint(submission_df.shape)\nsubmission_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}